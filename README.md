# ğŸ“œ Scraper de Proyectos de Ley - Congreso del PerÃº ğŸ‡µğŸ‡ª

[![CI/CD](https://github.com/ben1998pe/peru-congreso-leyes-scraper/workflows/CI/CD%20Pipeline/badge.svg)](https://github.com/ben1998pe/peru-congreso-leyes-scraper/actions)
[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

Este proyecto extrae, limpia y analiza datos de los proyectos de ley presentados en el Congreso del PerÃº desde su plataforma oficial: [https://wb2server.congreso.gob.pe/spley-portal/#/expediente/search](https://wb2server.congreso.gob.pe/spley-portal/#/expediente/search)

## ğŸš€ CaracterÃ­sticas Principales

### âœ¨ VersiÃ³n 2.0 - Mejorada
- **ğŸš€ Scraping Avanzado**: ExtracciÃ³n automÃ¡tica con Selenium y BeautifulSoup con manejo robusto de errores.
- **ğŸ” ValidaciÃ³n de Datos**: Sistema completo de validaciÃ³n y limpieza de datos
- **ğŸ“Š Monitoreo de Rendimiento**: Seguimiento en tiempo real del rendimiento del sistema
- **ğŸ› ï¸ CLI Completa**: Interfaz de lÃ­nea de comandos para todas las operaciones
- **ğŸ§ª Suite de Pruebas**: Cobertura completa de pruebas unitarias e integraciÃ³n
- **ğŸ“ˆ AnÃ¡lisis Avanzado**: Visualizaciones interactivas y reportes detallados
- **ğŸ”§ ConfiguraciÃ³n Flexible**: Sistema de configuraciÃ³n centralizado y personalizable
- **ğŸ“ Logging Mejorado**: Sistema de logging avanzado con rotaciÃ³n de archivos
- **ğŸš€ CI/CD**: Pipeline automatizado de integraciÃ³n y despliegue continuo

## ğŸ›  TecnologÃ­as Utilizadas

### Core
- **Python 3.8+**
- **Selenium 4.15+** - AutomatizaciÃ³n del navegador
- **BeautifulSoup 4.12+** - Parsing de HTML
- **pandas 2.1+** - ManipulaciÃ³n de datos
- **ChromeDriver** - Control del navegador Chrome

### AnÃ¡lisis y VisualizaciÃ³n
- **matplotlib 3.8+** - GrÃ¡ficos estÃ¡ticos
- **seaborn 0.13+** - Visualizaciones estadÃ­sticas
- **plotly 5.17+** - GrÃ¡ficos interactivos
- **jupyter** - Notebooks de anÃ¡lisis

### Utilidades
- **numpy 1.25+** - CÃ¡lculos numÃ©ricos
- **openpyxl 3.1+** - ExportaciÃ³n a Excel
- **tqdm 4.66+** - Barras de progreso

## ğŸ“ Estructura del Proyecto

```
peru-congreso-leyes-scraper/
â”œâ”€â”€ ğŸ“„ scraper.py                    # Scraper original (bÃ¡sico)
â”œâ”€â”€ ğŸ“„ scraper_mejorado.py           # Scraper mejorado (v1.0)
â”œâ”€â”€ ğŸ“„ scraper_enhanced.py           # Scraper mejorado v2.0 con validaciÃ³n y monitoreo
â”œâ”€â”€ ğŸ“„ cli.py                        # Interfaz de lÃ­nea de comandos
â”œâ”€â”€ ğŸ“„ config.py                     # ConfiguraciÃ³n centralizada
â”œâ”€â”€ ğŸ“„ ejemplo_uso.py                # Ejemplos de uso y menÃº interactivo
â”œâ”€â”€ ğŸ“„ requirements.txt              # Dependencias del proyecto
â”œâ”€â”€ ğŸ“„ setup.py                      # Script de instalaciÃ³n
â”œâ”€â”€ ğŸ“„ Makefile                      # Comandos de automatizaciÃ³n
â”œâ”€â”€ ğŸ“ config/                       # ConfiguraciÃ³n avanzada
â”‚   â””â”€â”€ environment.py               # GestiÃ³n de configuraciÃ³n por entorno
â”œâ”€â”€ ğŸ“ utils/                        # Utilidades mejoradas
â”‚   â”œâ”€â”€ limpieza.py                  # Limpieza de datos
â”‚   â”œâ”€â”€ logging_config.py            # ConfiguraciÃ³n de logging
â”‚   â”œâ”€â”€ data_validator.py            # ValidaciÃ³n de datos
â”‚   â””â”€â”€ performance_monitor.py       # Monitoreo de rendimiento
â”œâ”€â”€ ğŸ“ tests/                        # Suite de pruebas
â”‚   â””â”€â”€ test_scraper.py              # Pruebas unitarias e integraciÃ³n
â”œâ”€â”€ ğŸ“ .github/                      # ConfiguraciÃ³n de GitHub
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                   # Pipeline de CI/CD
â”œâ”€â”€ ğŸ“ data/                         # Datos extraÃ­dos (CSV)
â”‚   â”œâ”€â”€ proyectos_ley_*.csv
â”‚   â””â”€â”€ proyectos_ley_limpios_*.csv
â”œâ”€â”€ ğŸ“ notebooks/                    # AnÃ¡lisis exploratorio
â”‚   â””â”€â”€ analisis.ipynb
â”œâ”€â”€ ğŸ“ analysis/                     # Reportes y anÃ¡lisis
â”œâ”€â”€ ğŸ“ visualizations/               # GrÃ¡ficos exportados
â”œâ”€â”€ ğŸ“ logs/                         # Archivos de log
â””â”€â”€ ğŸ“„ chromedriver.exe              # Driver de Chrome
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/ben1998pe/peru-congreso-leyes-scraper.git
cd peru-congreso-leyes-scraper
```

### 2. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 3. Configurar ChromeDriver
- Descargar ChromeDriver compatible con tu versiÃ³n de Chrome
- Colocar `chromedriver.exe` en la raÃ­z del proyecto
- O usar `webdriver-manager` para descarga automÃ¡tica

### 4. Ejecutar ejemplo bÃ¡sico
```bash
python ejemplo_uso.py
```

### 5. Usar la CLI mejorada (Recomendado)
```bash
# Scraping bÃ¡sico
python cli.py scrape

# Scraping con fechas personalizadas
python cli.py scrape --fecha-desde "01/01/2024" --fecha-hasta "31/01/2024"

# Ver todas las opciones
python cli.py --help
```

### 6. Usar Makefile para automatizaciÃ³n
```bash
# Ver todas las opciones disponibles
make help

# ConfiguraciÃ³n completa del entorno de desarrollo
make dev-setup

# Ejecutar scraping
make scrape

# Ejecutar pruebas
make test
```

### 7. ConfiguraciÃ³n de entorno (Opcional)
```bash
# Copiar archivo de configuraciÃ³n de ejemplo
cp environment.example .env

# Editar configuraciÃ³n segÃºn necesidades
# nano .env
```

### 8. Configurar notificaciones (Opcional)
```bash
# Editar configuraciÃ³n de notificaciones
nano config/notifications.json

# Probar notificaciones
python cli.py notify --test
```

### 9. Usar el dashboard
```bash
# Ver dashboard en consola
make dashboard

# Generar dashboard HTML
make dashboard-html
```

## ğŸ“– GuÃ­a de Uso

### Uso BÃ¡sico

```python
from scraper_mejorado import CongresoScraper

# Crear scraper
scraper = CongresoScraper(headless=False)

# Scraping de Ãºltimos 7 dÃ­as
proyectos = scraper.scrape()

# Guardar datos
archivo = scraper.save_to_csv(proyectos)
print(f"Datos guardados en: {archivo}")

# Cerrar scraper
scraper.close()
```

### Uso Avanzado con Fechas Personalizadas

```python
from datetime import datetime, timedelta

# Definir rango de fechas
fecha_desde = "01/06/2025"
fecha_hasta = "15/06/2025"

scraper = CongresoScraper(headless=True)  # Modo headless
proyectos = scraper.scrape(fecha_desde, fecha_hasta)
```

### Limpieza y AnÃ¡lisis de Datos

```python
from utils.limpieza import DataCleaner, limpiar_archivo_csv

# Limpiar archivo existente
archivo_limpio = limpiar_archivo_csv("data/proyectos_ley_2025-06-05.csv")

# AnÃ¡lisis completo
cleaner = DataCleaner()
df_limpio = cleaner.limpiar_dataframe(df_raw)
resumen = cleaner.generar_resumen(df_limpio)
```

## ğŸ†• Nuevas Funcionalidades v2.0

### ğŸš€ Scraper Mejorado (`scraper_enhanced.py`)
- **Manejo Robusto de Errores**: Sistema avanzado de reintentos y recuperaciÃ³n de errores
- **ValidaciÃ³n de Datos**: ValidaciÃ³n automÃ¡tica de todos los datos extraÃ­dos
- **Monitoreo de Rendimiento**: Seguimiento en tiempo real del rendimiento del sistema
- **Logging Avanzado**: Sistema de logging con rotaciÃ³n de archivos y colores
- **MÃºltiples Selectores**: Fallbacks automÃ¡ticos para elementos de la pÃ¡gina web
- **Sistema de MÃ©tricas**: RecolecciÃ³n automÃ¡tica de mÃ©tricas de rendimiento y calidad

### ğŸ“Š Sistema de MÃ©tricas y Reportes
- **RecolecciÃ³n AutomÃ¡tica**: MÃ©tricas de sesiones, rendimiento y calidad de datos
- **AnÃ¡lisis de Tendencias**: Seguimiento de patrones de uso y rendimiento
- **Reportes Ejecutivos**: GeneraciÃ³n automÃ¡tica de resÃºmenes para stakeholders
- **Dashboard de MÃ©tricas**: VisualizaciÃ³n en tiempo real del estado del sistema
- **ExportaciÃ³n Avanzada**: Reportes en JSON, HTML y CSV para anÃ¡lisis externos

### ğŸš¨ Sistema de Alertas Inteligentes
- **Umbrales Configurables**: Alertas personalizables por tipo de mÃ©trica
- **MÃºltiples Canales**: Notificaciones por email, Slack, Discord y Teams
- **Cooldown Inteligente**: PrevenciÃ³n de spam de alertas
- **Severidad Graduada**: Alertas crÃ­ticas, altas, medias y bajas
- **ResoluciÃ³n Manual**: Sistema para marcar alertas como resueltas

### ğŸŒ Dashboard Web Interactivo
- **Monitoreo en Tiempo Real**: Estado del sistema actualizado automÃ¡ticamente
- **API REST Completa**: Endpoints para todas las funcionalidades
- **Visualizaciones Interactivas**: GrÃ¡ficos con Plotly para anÃ¡lisis dinÃ¡mico
- **Responsive Design**: Accesible desde cualquier dispositivo
- **ExportaciÃ³n Directa**: Descarga de datos en mÃºltiples formatos

### ğŸ“¤ ExportaciÃ³n Multi-Formato
- **Formatos Soportados**: CSV, Excel, JSON, HTML, XML, SQL, Parquet, ZIP
- **ExportaciÃ³n MÃºltiple**: Varios formatos simultÃ¡neamente
- **OptimizaciÃ³n AutomÃ¡tica**: Recomendaciones de formato segÃºn el tamaÃ±o de datos
- **Hojas de Resumen**: InformaciÃ³n estadÃ­stica incluida en Excel
- **CompresiÃ³n ZIP**: MÃºltiples archivos empaquetados

### ğŸ› ï¸ CLI Completa (`cli.py`)
```bash
# Comandos disponibles
python cli.py scrape          # Scraping con opciones avanzadas
python cli.py clean           # Limpieza de datos
python cli.py validate        # ValidaciÃ³n de calidad de datos
python cli.py analyze         # AnÃ¡lisis completo de datos
python cli.py monitor         # Monitoreo de rendimiento
python cli.py config          # Ver configuraciÃ³n actual
```

### ğŸ” Sistema de ValidaciÃ³n (`utils/data_validator.py`)
- **ValidaciÃ³n de Campos**: VerificaciÃ³n automÃ¡tica de formato y contenido
- **DetecciÃ³n de AnomalÃ­as**: IdentificaciÃ³n de datos inconsistentes
- **Reportes de ValidaciÃ³n**: Informes detallados de calidad de datos
- **Modo Estricto**: ValidaciÃ³n mÃ¡s estricta para datos crÃ­ticos

### ğŸ“Š Monitoreo de Rendimiento (`utils/performance_monitor.py`)
- **MÃ©tricas del Sistema**: CPU, memoria, disco, red
- **Alertas AutomÃ¡ticas**: Notificaciones cuando se exceden umbrales
- **ExportaciÃ³n de Datos**: ExportaciÃ³n de mÃ©tricas a JSON
- **Profiling de CÃ³digo**: MediciÃ³n de tiempo de ejecuciÃ³n de funciones

### ğŸ§ª Suite de Pruebas (`tests/`)
- **Pruebas Unitarias**: Cobertura completa de todas las funciones
- **Pruebas de IntegraciÃ³n**: VerificaciÃ³n de flujos completos
- **Pruebas Parametrizadas**: MÃºltiples casos de prueba con datos variados
- **Mocks y Fixtures**: SimulaciÃ³n de dependencias externas

### ğŸ”§ AutomatizaciÃ³n (`Makefile`)
```bash
make dev-setup         # ConfiguraciÃ³n completa del entorno
make test              # Ejecutar todas las pruebas
make quality           # Verificaciones de calidad de cÃ³digo
make pipeline          # Pipeline completo de datos
make analyze-complete  # AnÃ¡lisis completo automatizado
make health-check      # VerificaciÃ³n de salud del proyecto
make metrics-summary   # Mostrar resumen de mÃ©tricas
make metrics-export    # Exportar reporte de mÃ©tricas
make report-executive  # Generar resumen ejecutivo
make report-analytics  # Generar reporte de anÃ¡lisis
make report-metrics    # Generar reporte de mÃ©tricas
make alerts-list       # Listar alertas activas
make alerts-summary    # Mostrar resumen de alertas
make alerts-export     # Exportar alertas a archivo
make export-csv        # Exportar datos a CSV
make export-multiple   # Exportar datos en mÃºltiples formatos
make dashboard         # Mostrar dashboard en consola
make dashboard-html    # Generar dashboard HTML
make dashboard-web     # Iniciar dashboard web
make notify-test       # Probar sistema de notificaciones
```

### ğŸ“Š Scripts de AnÃ¡lisis (`scripts/`)
- **`run_analysis.py`**: AnÃ¡lisis completo automatizado con exportaciÃ³n de resultados
- **`health_check.py`**: VerificaciÃ³n de salud del proyecto y estructura

### ğŸ“ˆ Sistema de MÃ©tricas y Reportes (`utils/`)
- **`metrics_collector.py`**: RecolecciÃ³n avanzada de mÃ©tricas de rendimiento y calidad
- **`report_generator.py`**: GeneraciÃ³n automÃ¡tica de reportes ejecutivos y analÃ­ticos
- **`alert_system.py`**: Sistema de alertas inteligentes con umbrales configurables
- **`data_exporter.py`**: ExportaciÃ³n de datos en mÃºltiples formatos (CSV, Excel, JSON, HTML, XML, SQL, Parquet)

### ğŸŒ Dashboard Web Interactivo
- **`web_dashboard.py`**: Dashboard web con Flask para monitoreo en tiempo real
- **API REST**: Endpoints para mÃ©tricas, alertas, datos y grÃ¡ficos
- **Visualizaciones**: GrÃ¡ficos interactivos con Plotly
- **Monitoreo**: Estado del sistema, alertas activas y mÃ©tricas en tiempo real

### ğŸ““ Notebook Mejorado (`notebooks/analisis.ipynb`)
- **ValidaciÃ³n automÃ¡tica**: VerificaciÃ³n de calidad de datos integrada
- **ExportaciÃ³n avanzada**: GeneraciÃ³n automÃ¡tica de reportes HTML y JSON
- **AnÃ¡lisis interactivo**: Visualizaciones mejoradas con Plotly
- **Reportes automÃ¡ticos**: GeneraciÃ³n de reportes HTML profesionales

### ğŸ”” Sistema de Notificaciones (`utils/notifications.py`)
- **MÃºltiples canales**: Email, Slack, Telegram
- **Notificaciones automÃ¡ticas**: Inicio, finalizaciÃ³n y errores de scraping
- **ConfiguraciÃ³n flexible**: JSON configuraciÃ³n para diferentes canales
- **Pruebas integradas**: Sistema de testing de notificaciones

### ğŸ“Š Dashboard de Monitoreo (`dashboard.py`)
- **Estado en tiempo real**: Monitoreo del estado del proyecto
- **MÃ©tricas visuales**: EstadÃ­sticas de datos y rendimiento
- **Dashboard HTML**: Interfaz web interactiva con auto-actualizaciÃ³n
- **Logs en vivo**: VisualizaciÃ³n de logs recientes con colores

## ğŸ“Š Funcionalidades del Scraper Mejorado

### âœ¨ CaracterÃ­sticas Principales

1. **Manejo de Fechas Flexible**
   - Rango de fechas personalizable
   - Fechas por defecto (Ãºltimos 7 dÃ­as)
   - ValidaciÃ³n de formato de fechas

2. **PaginaciÃ³n AutomÃ¡tica**
   - DetecciÃ³n automÃ¡tica de pÃ¡ginas mÃºltiples
   - NavegaciÃ³n secuencial entre pÃ¡ginas
   - Manejo de timeouts y errores

3. **Limpieza de Datos Avanzada**
   - NormalizaciÃ³n de fechas y proyectos
   - ExtracciÃ³n de partidos polÃ­ticos
   - ClasificaciÃ³n automÃ¡tica de tipos de proyectos
   - DetecciÃ³n de regiones geogrÃ¡ficas
   - AnÃ¡lisis de colaboraciones entre congresistas

4. **Sistema de Logging**
   - Logs detallados de todas las operaciones
   - RotaciÃ³n automÃ¡tica de archivos de log
   - Niveles de logging configurables

5. **ConfiguraciÃ³n Centralizada**
   - ParÃ¡metros en archivo `config.py`
   - Selectores CSS/XPath configurables
   - Timeouts y delays ajustables

### ğŸ” Datos ExtraÃ­dos

- **Proyecto**: NÃºmero y cÃ³digo del proyecto de ley
- **Fecha**: Fecha de presentaciÃ³n (normalizada)
- **TÃ­tulo**: TÃ­tulo completo del proyecto
- **Estado**: Estado procesal actual
- **Proponente**: Entidad proponente
- **Autores**: Lista de congresistas autores
- **Partido PolÃ­tico**: ExtraÃ­do automÃ¡ticamente
- **Tipo de Proyecto**: Clasificado automÃ¡ticamente
- **RegiÃ³n**: RegiÃ³n mencionada en el proyecto
- **Metadatos**: AÃ±o, mes, dÃ­a de la semana, etc.

## ğŸ“ˆ AnÃ¡lisis y Visualizaciones

### Notebook de AnÃ¡lisis (`notebooks/analisis.ipynb`)

1. **Carga y Limpieza de Datos**
2. **AnÃ¡lisis Descriptivo**
3. **AnÃ¡lisis Temporal**
4. **AnÃ¡lisis por Partido PolÃ­tico**
5. **AnÃ¡lisis por Tipo de Proyecto**
6. **AnÃ¡lisis de Autores y Colaboraciones**
7. **Visualizaciones Interactivas**

### Tipos de Visualizaciones

- **GrÃ¡ficos de Barras**: Proyectos por partido/regiÃ³n/tipo
- **GrÃ¡ficos de Torta**: DistribuciÃ³n de tipos de proyectos
- **Timeline**: EvoluciÃ³n temporal de proyectos
- **Heatmaps**: Actividad por congresista
- **Word Clouds**: Temas mÃ¡s frecuentes

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Archivo `config.py`

```python
# ConfiguraciÃ³n del navegador
CHROME_OPTIONS = [
    "--start-maximized",
    "--no-sandbox",
    "--disable-dev-shm-usage"
]

# Timeouts y delays
WAIT_TIMEOUT = 15
PAGE_LOAD_DELAY = 3
SEARCH_DELAY = 5

# Rango de fechas por defecto
DEFAULT_DATE_RANGE = 7  # dÃ­as hacia atrÃ¡s

# ConfiguraciÃ³n de logging
LOG_LEVEL = "INFO"
LOG_FILE = "logs/scraper_20250605.log"
```

## ğŸ› SoluciÃ³n de Problemas

### Errores Comunes

1. **ChromeDriver no encontrado**
   ```bash
   # Descargar ChromeDriver compatible
   # O usar webdriver-manager
   pip install webdriver-manager
   ```

2. **Timeout en elementos**
   - Aumentar `WAIT_TIMEOUT` en `config.py`
   - Verificar conectividad a internet
   - Verificar que el sitio web estÃ© disponible

3. **Datos mal formateados**
   - Ejecutar limpieza de datos con `utils/limpieza.py`
   - Verificar logs para errores de parsing

4. **Memoria insuficiente**
   - Usar modo headless: `CongresoScraper(headless=True)`
   - Procesar datos en lotes mÃ¡s pequeÃ±os

### Logs y Debugging

Los logs se guardan en `logs/scraper_YYYYMMDD.log` con informaciÃ³n detallada:
- NavegaciÃ³n entre pÃ¡ginas
- Elementos encontrados/no encontrados
- Errores de parsing
- EstadÃ­sticas de extracciÃ³n

## ğŸ“Š Ejemplos de AnÃ¡lisis

### EstadÃ­sticas BÃ¡sicas
```python
# Total de proyectos por partido
df_clean['partido_politico'].value_counts()

# Proyectos por tipo
df_clean['tipo_proyecto'].value_counts()

# Congresista mÃ¡s activo
todos_autores = []
for autores in df_clean['autores_limpios']:
    todos_autores.extend(autores)
pd.Series(todos_autores).value_counts().head(1)
```

### AnÃ¡lisis Temporal
```python
# Proyectos por mes
df_clean.groupby([df_clean['fecha_datetime'].dt.year, 
                 df_clean['fecha_datetime'].dt.month]).size()

# Proyectos por dÃ­a de la semana
df_clean['dia_semana'].value_counts()
```

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

## ğŸ†• Funcionalidades Avanzadas v3.0

### ğŸš¨ Sistema de Alertas Inteligentes

El sistema de alertas permite monitorear el rendimiento del scraper y recibir notificaciones automÃ¡ticas cuando se detectan problemas.

```bash
# Gestionar alertas
python cli.py alerts --list           # Listar alertas activas
python cli.py alerts --summary        # Mostrar resumen de alertas
python cli.py alerts --resolve 0      # Resolver alerta por ID
python cli.py alerts --export alerts.json  # Exportar alertas

# Comandos Makefile
make alerts-list                       # Listar alertas activas
make alerts-summary                    # Mostrar resumen de alertas
make alerts-export                     # Exportar alertas a archivo
```

**CaracterÃ­sticas:**
- Umbrales configurables por tipo de mÃ©trica
- Notificaciones por email, Slack, Discord y Teams
- Sistema de cooldown para evitar spam
- Alertas graduadas por severidad (crÃ­tica, alta, media, baja)

### ğŸ“¤ ExportaciÃ³n Multi-Formato

Exporta tus datos en mÃºltiples formatos para diferentes necesidades de anÃ¡lisis.

```bash
# Exportar en formato Ãºnico
python cli.py export --input data/proyectos_ley_2024-01-15.csv --format excel
python cli.py export --input data/proyectos_ley_2024-01-15.csv --format json
python cli.py export --input data/proyectos_ley_2024-01-15.csv --format html

# Exportar en mÃºltiples formatos
python cli.py export --input data/proyectos_ley_2024-01-15.csv --multiple --formats csv excel json html

# Comandos Makefile
make export-csv                        # Exportar a CSV
make export-multiple                   # Exportar en mÃºltiples formatos
```

**Formatos soportados:**
- **CSV**: Para anÃ¡lisis en Excel o herramientas de datos
- **Excel**: Con hojas de resumen y formato profesional
- **JSON**: Para integraciÃ³n con APIs y aplicaciones web
- **HTML**: Reportes web con visualizaciones
- **XML**: Para sistemas legacy y intercambio de datos
- **SQL**: Scripts de inserciÃ³n para bases de datos
- **Parquet**: Formato optimizado para big data
- **ZIP**: MÃºltiples formatos empaquetados

### ğŸŒ Dashboard Web Interactivo

Dashboard web completo para monitoreo en tiempo real del sistema.

```bash
# Iniciar dashboard web
python cli.py dashboard --port 5000 --host 0.0.0.0

# Comando Makefile
make dashboard-web                     # Iniciar dashboard web en puerto 5000

# Acceder al dashboard
# http://localhost:5000 - Dashboard principal
# http://localhost:5000/api/status - API de estado
# http://localhost:5000/api/metrics - API de mÃ©tricas
# http://localhost:5000/api/alerts - API de alertas
```

**CaracterÃ­sticas:**
- Monitoreo en tiempo real del estado del sistema
- GrÃ¡ficos interactivos con Plotly
- API REST completa para integraciÃ³n
- Responsive design para mÃ³viles y tablets
- ExportaciÃ³n directa de datos desde la interfaz

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## âœï¸ Autor(es)

**Benjamin Oscco Arias**
- GitHub: [@ben1998pe](https://github.com/ben1998pe)
- LinkedIn: [Benjamin Oscco](https://linkedin.com/in/benjamin-oscco)

## ğŸ™ Agradecimientos

- Al Congreso del PerÃº por proporcionar acceso pÃºblico a los datos
- A la comunidad de Python por las excelentes librerÃ­as utilizadas
- A todos los contribuidores del proyecto

---

**âš ï¸ Nota Legal**: Este proyecto es solo para fines educativos y de investigaciÃ³n. Respete los tÃ©rminos de uso del sitio web del Congreso del PerÃº.
