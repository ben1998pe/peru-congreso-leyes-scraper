# ğŸ“œ Scraper de Proyectos de Ley - Congreso del PerÃº ğŸ‡µğŸ‡ª

Este proyecto extrae, limpia y analiza datos de los proyectos de ley presentados en el Congreso del PerÃº desde su plataforma oficial: [https://wb2server.congreso.gob.pe/spley-portal/#/expediente/search](https://wb2server.congreso.gob.pe/spley-portal/#/expediente/search)

## ğŸš€ CaracterÃ­sticas Principales

- **Web Scraping Avanzado**: ExtracciÃ³n automÃ¡tica con Selenium y BeautifulSoup
- **Limpieza de Datos**: NormalizaciÃ³n y enriquecimiento de informaciÃ³n
- **AnÃ¡lisis Exploratorio**: Visualizaciones interactivas con Plotly
- **ConfiguraciÃ³n Flexible**: Rango de fechas personalizable y paginaciÃ³n automÃ¡tica
- **Logging Completo**: Monitoreo y debugging detallado
- **ExportaciÃ³n MÃºltiple**: CSV, anÃ¡lisis y reportes automÃ¡ticos

## ğŸ›  TecnologÃ­as Utilizadas

### Core
- **Python 3.8+**
- **Selenium 4.15+** - AutomatizaciÃ³n del navegador
- **BeautifulSoup 4.12+** - Parsing de HTML
- **pandas 2.1+** - ManipulaciÃ³n de datos
- **ChromeDriver** - Control del navegador Chrome

### AnÃ¡lisis y VisualizaciÃ³n
- **matplotlib 3.8+** - GrÃ¡ficos estÃ¡ticos
- **seaborn 0.13+** - Visualizaciones estadÃ­sticas
- **plotly 5.17+** - GrÃ¡ficos interactivos
- **jupyter** - Notebooks de anÃ¡lisis

### Utilidades
- **numpy 1.25+** - CÃ¡lculos numÃ©ricos
- **openpyxl 3.1+** - ExportaciÃ³n a Excel
- **tqdm 4.66+** - Barras de progreso

## ğŸ“ Estructura del Proyecto

```
peru-congreso-leyes-scraper/
â”œâ”€â”€ ğŸ“„ scraper.py              # Scraper original (bÃ¡sico)
â”œâ”€â”€ ğŸ“„ scraper_mejorado.py     # Scraper mejorado con todas las funcionalidades
â”œâ”€â”€ ğŸ“„ config.py               # ConfiguraciÃ³n centralizada
â”œâ”€â”€ ğŸ“„ ejemplo_uso.py          # Ejemplos de uso y menÃº interactivo
â”œâ”€â”€ ğŸ“„ requirements.txt        # Dependencias del proyecto
â”œâ”€â”€ ğŸ“ data/                   # Datos extraÃ­dos (CSV)
â”‚   â”œâ”€â”€ proyectos_ley_*.csv
â”‚   â””â”€â”€ proyectos_ley_limpios_*.csv
â”œâ”€â”€ ğŸ“ notebooks/              # AnÃ¡lisis exploratorio
â”‚   â””â”€â”€ analisis.ipynb
â”œâ”€â”€ ğŸ“ utils/                  # Funciones auxiliares
â”‚   â””â”€â”€ limpieza.py
â”œâ”€â”€ ğŸ“ analysis/               # Reportes y anÃ¡lisis
â”œâ”€â”€ ğŸ“ visualizations/         # GrÃ¡ficos exportados
â”œâ”€â”€ ğŸ“ logs/                   # Archivos de log
â””â”€â”€ ğŸ“„ chromedriver.exe        # Driver de Chrome
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/ben1998pe/peru-congreso-leyes-scraper.git
cd peru-congreso-leyes-scraper
```

### 2. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 3. Configurar ChromeDriver
- Descargar ChromeDriver compatible con tu versiÃ³n de Chrome
- Colocar `chromedriver.exe` en la raÃ­z del proyecto
- O usar `webdriver-manager` para descarga automÃ¡tica

### 4. Ejecutar ejemplo bÃ¡sico
```bash
python ejemplo_uso.py
```

## ğŸ“– GuÃ­a de Uso

### Uso BÃ¡sico

```python
from scraper_mejorado import CongresoScraper

# Crear scraper
scraper = CongresoScraper(headless=False)

# Scraping de Ãºltimos 7 dÃ­as
proyectos = scraper.scrape()

# Guardar datos
archivo = scraper.save_to_csv(proyectos)
print(f"Datos guardados en: {archivo}")

# Cerrar scraper
scraper.close()
```

### Uso Avanzado con Fechas Personalizadas

```python
from datetime import datetime, timedelta

# Definir rango de fechas
fecha_desde = "01/06/2025"
fecha_hasta = "15/06/2025"

scraper = CongresoScraper(headless=True)  # Modo headless
proyectos = scraper.scrape(fecha_desde, fecha_hasta)
```

### Limpieza y AnÃ¡lisis de Datos

```python
from utils.limpieza import DataCleaner, limpiar_archivo_csv

# Limpiar archivo existente
archivo_limpio = limpiar_archivo_csv("data/proyectos_ley_2025-06-05.csv")

# AnÃ¡lisis completo
cleaner = DataCleaner()
df_limpio = cleaner.limpiar_dataframe(df_raw)
resumen = cleaner.generar_resumen(df_limpio)
```

## ğŸ“Š Funcionalidades del Scraper Mejorado

### âœ¨ CaracterÃ­sticas Principales

1. **Manejo de Fechas Flexible**
   - Rango de fechas personalizable
   - Fechas por defecto (Ãºltimos 7 dÃ­as)
   - ValidaciÃ³n de formato de fechas

2. **PaginaciÃ³n AutomÃ¡tica**
   - DetecciÃ³n automÃ¡tica de pÃ¡ginas mÃºltiples
   - NavegaciÃ³n secuencial entre pÃ¡ginas
   - Manejo de timeouts y errores

3. **Limpieza de Datos Avanzada**
   - NormalizaciÃ³n de fechas y proyectos
   - ExtracciÃ³n de partidos polÃ­ticos
   - ClasificaciÃ³n automÃ¡tica de tipos de proyectos
   - DetecciÃ³n de regiones geogrÃ¡ficas
   - AnÃ¡lisis de colaboraciones entre congresistas

4. **Sistema de Logging**
   - Logs detallados de todas las operaciones
   - RotaciÃ³n automÃ¡tica de archivos de log
   - Niveles de logging configurables

5. **ConfiguraciÃ³n Centralizada**
   - ParÃ¡metros en archivo `config.py`
   - Selectores CSS/XPath configurables
   - Timeouts y delays ajustables

### ğŸ” Datos ExtraÃ­dos

- **Proyecto**: NÃºmero y cÃ³digo del proyecto de ley
- **Fecha**: Fecha de presentaciÃ³n (normalizada)
- **TÃ­tulo**: TÃ­tulo completo del proyecto
- **Estado**: Estado procesal actual
- **Proponente**: Entidad proponente
- **Autores**: Lista de congresistas autores
- **Partido PolÃ­tico**: ExtraÃ­do automÃ¡ticamente
- **Tipo de Proyecto**: Clasificado automÃ¡ticamente
- **RegiÃ³n**: RegiÃ³n mencionada en el proyecto
- **Metadatos**: AÃ±o, mes, dÃ­a de la semana, etc.

## ğŸ“ˆ AnÃ¡lisis y Visualizaciones

### Notebook de AnÃ¡lisis (`notebooks/analisis.ipynb`)

1. **Carga y Limpieza de Datos**
2. **AnÃ¡lisis Descriptivo**
3. **AnÃ¡lisis Temporal**
4. **AnÃ¡lisis por Partido PolÃ­tico**
5. **AnÃ¡lisis por Tipo de Proyecto**
6. **AnÃ¡lisis de Autores y Colaboraciones**
7. **Visualizaciones Interactivas**

### Tipos de Visualizaciones

- **GrÃ¡ficos de Barras**: Proyectos por partido/regiÃ³n/tipo
- **GrÃ¡ficos de Torta**: DistribuciÃ³n de tipos de proyectos
- **Timeline**: EvoluciÃ³n temporal de proyectos
- **Heatmaps**: Actividad por congresista
- **Word Clouds**: Temas mÃ¡s frecuentes

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Archivo `config.py`

```python
# ConfiguraciÃ³n del navegador
CHROME_OPTIONS = [
    "--start-maximized",
    "--no-sandbox",
    "--disable-dev-shm-usage"
]

# Timeouts y delays
WAIT_TIMEOUT = 15
PAGE_LOAD_DELAY = 3
SEARCH_DELAY = 5

# Rango de fechas por defecto
DEFAULT_DATE_RANGE = 7  # dÃ­as hacia atrÃ¡s

# ConfiguraciÃ³n de logging
LOG_LEVEL = "INFO"
LOG_FILE = "logs/scraper_20250605.log"
```

## ğŸ› SoluciÃ³n de Problemas

### Errores Comunes

1. **ChromeDriver no encontrado**
   ```bash
   # Descargar ChromeDriver compatible
   # O usar webdriver-manager
   pip install webdriver-manager
   ```

2. **Timeout en elementos**
   - Aumentar `WAIT_TIMEOUT` en `config.py`
   - Verificar conectividad a internet
   - Verificar que el sitio web estÃ© disponible

3. **Datos mal formateados**
   - Ejecutar limpieza de datos con `utils/limpieza.py`
   - Verificar logs para errores de parsing

4. **Memoria insuficiente**
   - Usar modo headless: `CongresoScraper(headless=True)`
   - Procesar datos en lotes mÃ¡s pequeÃ±os

### Logs y Debugging

Los logs se guardan en `logs/scraper_YYYYMMDD.log` con informaciÃ³n detallada:
- NavegaciÃ³n entre pÃ¡ginas
- Elementos encontrados/no encontrados
- Errores de parsing
- EstadÃ­sticas de extracciÃ³n

## ğŸ“Š Ejemplos de AnÃ¡lisis

### EstadÃ­sticas BÃ¡sicas
```python
# Total de proyectos por partido
df_clean['partido_politico'].value_counts()

# Proyectos por tipo
df_clean['tipo_proyecto'].value_counts()

# Congresista mÃ¡s activo
todos_autores = []
for autores in df_clean['autores_limpios']:
    todos_autores.extend(autores)
pd.Series(todos_autores).value_counts().head(1)
```

### AnÃ¡lisis Temporal
```python
# Proyectos por mes
df_clean.groupby([df_clean['fecha_datetime'].dt.year, 
                 df_clean['fecha_datetime'].dt.month]).size()

# Proyectos por dÃ­a de la semana
df_clean['dia_semana'].value_counts()
```

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## âœï¸ Autor

**Benjamin Oscco Arias**
- GitHub: [@ben1998pe](https://github.com/ben1998pe)
- LinkedIn: [Benjamin Oscco](https://linkedin.com/in/benjamin-oscco)

## ğŸ™ Agradecimientos

- Al Congreso del PerÃº por proporcionar acceso pÃºblico a los datos
- A la comunidad de Python por las excelentes librerÃ­as utilizadas
- A todos los contribuidores del proyecto

---

**âš ï¸ Nota Legal**: Este proyecto es solo para fines educativos y de investigaciÃ³n. Respete los tÃ©rminos de uso del sitio web del Congreso del PerÃº.
